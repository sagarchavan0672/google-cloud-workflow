main:
    steps:
      - load_env_details:
          call:  read_env_from_gcs
          args:
                bucket:  {{config_file_bucke}}
                object:  {{config_json_file.json}}
          result:  env_details
      
      - extract_table_config:
          assign:
            - ls: []
            - list_ex: []
            - tables_ls: ${env_details.body.tables}           

      - iterate_ls:
            for:
                value: itm
                in: ${tables_ls}
                steps:
                   - assign_v:
                        assign:
                          - bucket:  ${itm.bucket}
                          - projectid: ${itm.projectid}
                          - prefix: ${itm.prefix}
                          - bq_dataset: ${itm.bq_dataset}
                          - imp_user: ${itm.imp_user}
                          - instance: ${itm.instance}
                          - databaseschema: ${itm.databaseschema}
                          - query:  ${itm.query}
                          - table_name: ${itm.table_name}
                          - stage_table: ${itm.stage_table}
                          - merge_script: ${itm.merge_script}
                          - i: 0
                          - j: 0
                          - listResult:
                              nextPageToken: ""
                          - ls_dict: []
                          - dict: 
                              src_table: ""
                              tar_table: ""
                              ps_stage_table: ""
                              prfx: ""
                              queries: ""
                              merge: ""
                          - ls_prefix: []

                   - assign_prefix:
                        assign: 
                            - prefix_with_folder: ${table_name + "/" + prefix}
                            - dict: 
                                src_table: ${table_name}
                                tar_table: ${table_name} #target_table[i]
                                ps_stage_table: ${stage_table}
                                prfx: ${prefix_with_folder}
                                queries: ${query}
                                merge: ${merge_script}
                            - ls_dict: ${list.concat(ls_dict, dict)}

                   - export_query:
                        call: googleapis.bigquery.v2.jobs.query
                        args:
                            projectId: ${projectid}
                            body:
                                query: ${"EXPORT DATA OPTIONS( uri='gs://" + bucket + "/" + prefix_with_folder + table_name+"*.csv', format='CSV', overwrite=true,header=false) AS " + query}
                                useLegacySql: false

                   - importfiles:
                        call: list_file_to_import
                        args:
                            pagetoken: ${listResult.nextPageToken}
                            bucket: ${bucket}
                            prefix: ${prefix_with_folder}
                            projectid: ${projectid}
                            instance: ${instance}
                            databaseschema: ${databaseschema}
                            importtable: ${stage_table}
                        result: listResult
                        next: export_stage_to_main

                    # Merge data in final table 
                    # Truncate stage table
                   - export_stage_to_main:
                        call: stage_to_main
                        args:
                            imp_user: ${imp_user}
                            projectid: ${projectid}
                            instance: ${instance}
                            databaseschema: ${databaseschema}
                            merge_script: ${merge_script}

      - final:
                return: ${tables_ls}
               
      
      
read_env_from_gcs:
    params:  [bucket,  object]
    steps:
    - read_from_gcs:
        call:  http.get
        args:
            url:  ${"https://storage.googleapis.com/download/storage/v1/b/"  +  bucket  +  "/o/"  +  object}
            auth:
                type:  OAuth2
            query:
                alt:  media
        result:  env_file_json_content
    - return_content:
        return:  ${env_file_json_content}



list_file_to_import:
    params:
      - pagetoken
      - bucket
      - prefix
      - projectid
      - instance
      - databaseschema
      - importtable
     
    steps:
      - list-files:
          call: googleapis.storage.v1.objects.list
          args:
            bucket: ${bucket}
            pageToken: ${pagetoken}
            prefix: ${prefix}
          result: listResult
          
      - process-files:
          for:
            value: file
            in: ${listResult.items} 
            steps:
            
              - wait-import:
                  call: import_file
                  args:
                    projectid: ${projectid}
                    instance: ${instance}
                    databaseschema: ${databaseschema}
                    importtable: ${importtable}
                    file: ${"gs://" + bucket + "/" + file.name}     
          
      - return-step:
          return: ${listResult}
  
  
import_file:
    params:
      - projectid
      - instance
      - databaseschema
      - importtable
      - file

    steps:


      - callImport:
          call: http.post
          args:
            url: ${"https://sqladmin.googleapis.com/v1/projects/" + projectid + "/instances/" + instance + "/import"}
            auth:
              type: OAuth2
            body:
              importContext:
                uri: ${file}
                database: ${databaseschema}
                fileType: CSV
                csvImportOptions:
                  table: ${importtable}
          result: operation
      
      - chekoperation:
          switch:
            - condition: ${operation.body.status != "DONE"}
              next: wait
          next: completed
          
      - completed:
          return: file
          
          
      - wait:
          call: sys.sleep
          args:
            seconds: 1
          next: getoperation
          
      - getoperation:
          call: http.get
          args:
            url: ${operation.body.selfLink}
            auth:
              type: OAuth2
          result: operation
          next: chekoperation

stage_to_main:
  params:
      - projectid
      - instance
      - databaseschema
      - merge_script
      - imp_user

  steps:

    - export_stage_to_main:
                  call: http.post
                  args:
                      url: ${"https://sqladmin.googleapis.com/v1/projects/" + projectid + "/instances/" + instance + "/import"}
                      auth:
                          type: OAuth2
                      body:
                          importContext:
                              uri: ${merge_script}
                              database: ${databaseschema}
                              fileType: "SQL"
                              importUser: ${imp_user}
                  result: operation
                  
    - chekoperation:
          switch:
            - condition: ${operation.body.status != "DONE"}
              next: wait
          next: completed
          
    - completed:
          return: file
          
    - wait:
          call: sys.sleep
          args:
            seconds: 1
          next: getoperation
          
    - getoperation:
          call: http.get
          args:
            url: ${operation.body.selfLink}
            auth:
              type: OAuth2
          result: operation
          next: chekoperation
